{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Exploratory Data Analysis\n",
    "#### Initial General Notes: There is an imbalance of classes in the data as there are multiple organs in the image of the abdomen other than the pancreas. There are no missing data as the image to label ratio is clearly 1:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_intensity_distribution(dataloader, num_batches=1, samples_per_volume=100000):\n",
    "    volume_intensities = []\n",
    "    label_intensities = []\n",
    "\n",
    "    for i, (volume, label) in enumerate(dataloader):\n",
    "\n",
    "        # Stopping criteria\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "        # Squeeze out channel and batch singleton dimensions\n",
    "        volume = volume.squeeze().numpy()\n",
    "        label = label.squeeze().numpy()\n",
    "\n",
    "        # Iterate through each slice in batch\n",
    "        for vol_slice, lbl_slice in zip(volume, label):\n",
    "\n",
    "            # Filter out padding values\n",
    "            non_padded_pixels = vol_slice[vol_slice > 0]  # Adjust this threshold as needed\n",
    "            labeled_pixels = vol_slice[lbl_slice > 0]\n",
    "\n",
    "            # Randomly sample pixels to reduce the data size\n",
    "            if len(non_padded_pixels) > samples_per_volume:\n",
    "                sampled_volume_pixels = np.random.choice(non_padded_pixels, samples_per_volume, replace=False)\n",
    "            else:\n",
    "                sampled_volume_pixels = non_padded_pixels\n",
    "            \n",
    "            if len(labeled_pixels) > samples_per_volume:\n",
    "                sampled_label_pixels = np.random.choice(labeled_pixels, samples_per_volume, replace=False)\n",
    "            else:\n",
    "                sampled_label_pixels = labeled_pixels\n",
    "\n",
    "            volume_intensities.extend(sampled_volume_pixels)\n",
    "            label_intensities.extend(sampled_label_pixels)\n",
    "    \n",
    "    # Plot the histogram of the sampled intensities\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    axs[0].hist(volume_intensities, bins=256, color='skyblue', alpha=0.75)  # Adjust bins if needed\n",
    "    axs[0].set_title('Pixel Intensity Distribution of Volumes')\n",
    "    axs[0].set_xlabel('Pixel Intensity')\n",
    "    axs[0].set_ylabel('Frequency')\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    axs[1].hist(label_intensities, bins=30, color='lightcoral', alpha=0.75)  # Adjust bins if needed\n",
    "    axs[1].set_title('Pixel Intensity Distribution of Labeled Pancreas')\n",
    "    axs[1].set_xlabel('Pixel Intensity')\n",
    "    axs[1].set_ylabel('Frequency')\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def create_data_loaders(dataset, batch_size=1):\n",
    "\n",
    "    # Determine sizes of each split\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Randomly split the dataset into train, cv, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(832) # Set seed\n",
    "    )\n",
    "\n",
    "    # Create data loaders for each split\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create dataloaders\n",
    "dataset = MedicalImageDataset(image_root_dir, label_root_dir, transforms=transforms)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(dataset, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
