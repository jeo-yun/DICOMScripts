{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression and SVM models for Segmentation of Pancreas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 12:32:13.384786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from monai.data import Dataset\n",
    "from monai.transforms import LoadImage\n",
    "\n",
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        # the self.patients list is filled with the names of directories in image_dir when then directory name includes \"PANCREAS\"\n",
    "        self.patients = [f for f in sorted(os.listdir(image_dir)) if \"PANCREAS\" in f]\n",
    "        self.max_depth = self.calculate_max_depth()\n",
    "\n",
    "    def calculate_max_depth(self):\n",
    "        max_depth = 0\n",
    "        for patient_folder in self.patients:\n",
    "            patient_image_dir = os.path.join(self.image_dir, patient_folder)\n",
    "            volume = self.load_dicom_volume(patient_image_dir) # finds the number of slices in the folder\n",
    "            if volume.shape[0] > max_depth:\n",
    "                max_depth = volume.shape[0]\n",
    "        return max_depth\n",
    "\n",
    "    def load_dicom_volume(self, patient_image_dir):\n",
    "        subfolder = next(os.walk(patient_image_dir))[1][0]\n",
    "        deepest_folder = next(os.walk(os.path.join(patient_image_dir, subfolder)))[1][0]\n",
    "        final_path = os.path.join(patient_image_dir, subfolder, deepest_folder)\n",
    "        files = sorted(os.listdir(final_path), key=lambda x: pydicom.dcmread(os.path.join(final_path, x)).InstanceNumber)\n",
    "        # os.listdir(final_path): refers to the folder with the dicom files\n",
    "        # sorted() usually sorts them in alphabetical, but using the key parameter makes sure a specific order is used\n",
    "        # key=lambda x: pydicom.dcmread(os.path.join(final_path, x)).InstanceNumber:\n",
    "            # lambda x: defines an anonymous function where x is the name of the variable that represents each element in the list\n",
    "            # pydicom.dcmread(os.path.join(final_path, x)).InstanceNumber : the instance number of each dicom image is used to ensure that the images are sorted in consecutive, sequential order.\n",
    "\n",
    "        # stacks all of the 2D slices for each patient into a 3D array\n",
    "        volume = np.stack([pydicom.dcmread(os.path.join(final_path, f)).pixel_array for f in files])\n",
    "\n",
    "        # converts the numpy array into a torch tensor\n",
    "        return torch.from_numpy(volume).float()  # No need to add batch dimension manually\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_folder = self.patients[idx]\n",
    "        patient_image_dir = os.path.join(self.image_dir, patient_folder)\n",
    "        patient_label_path = os.path.join(self.label_dir, f\"label{patient_folder.split('_')[-1]}.nii.gz\")\n",
    "        \n",
    "        volume = self.load_dicom_volume(patient_image_dir)\n",
    "\n",
    "        # label image is loaded with MONAI's LoadImage where only the image is loaded with image_only = True\n",
    "        label = LoadImage(image_only=True)(patient_label_path)\n",
    "        # rearranges the axes of the label array to match the conventional layout expected by PyTorch models (num_channels x height x width)\n",
    "        label = np.transpose(label, (2, 0, 1))\n",
    "        # turns numpy array into torch tensor\n",
    "        label = torch.from_numpy(label).float()\n",
    "\n",
    "        # Padding to maximum depth for depth (slice axis)\n",
    "        pad_size = self.max_depth - volume.shape[0]\n",
    "        volume = torch.nn.functional.pad(volume, (0, 0, 0, 0, 0, pad_size))\n",
    "        label = torch.nn.functional.pad(label, (0, 0, 0, 0, 0, pad_size))\n",
    "\n",
    "        # Correcting shape to (512, 512, padded_num_slices, 1)\n",
    "        volume = volume.permute(2, 1, 0).unsqueeze(-1)  # changes the shape of the volume tensor to fit the format expected by neural networks of (H, W, D, C)\n",
    "        # permute function allows for changing dimensions of the tensor\n",
    "        # unsqueeze function adds a new dimension at the specified index. Here the index is -1 which indicates that the new dimension added into the last position. \n",
    "        label = label.permute(2, 1, 0).unsqueeze(-1)    # changes the shape of the volume tensor to fit the format expected by neural networks of (H, W, D, C)\n",
    "\n",
    "        if self.transforms:\n",
    "            volume = self.transforms(volume)\n",
    "            label = self.transforms(label)\n",
    "\n",
    "        return volume.squeeze(0), label.squeeze(0)  # Ensure removing any singleton dimension at batch axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume shape: torch.Size([512, 512, 466, 1]) Label shape: torch.Size([512, 512, 466, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from monai.transforms import Compose, ScaleIntensity, EnsureType\n",
    "from monai.transforms import LoadImage\n",
    "\n",
    "# Transforms and DataLoader\n",
    "transforms = Compose([\n",
    "    ScaleIntensity(), # normalizes or scales image intensities\n",
    "    EnsureType(dtype=torch.float32) # ensures that the data type of the tensors after transformationis torch.float32 which is standard for PyTorch models\n",
    "])\n",
    "\n",
    "# Paths\n",
    "image_root_dir = \"/Users/lukeyun/SDS323/manifest-1599750808610/Pancreas-CT\"\n",
    "label_root_dir = \"/Users/lukeyun/SDS323/TCIA_pancreas_labels-02-05-2017\"\n",
    "\n",
    "dataset = MedicalImageDataset(image_root_dir, label_root_dir, transforms=transforms)\n",
    "\n",
    "# DataLoader is initialized which is standard for PyTorch usage\n",
    "\"\"\" dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "# note that the dataset has volume, label at this point\n",
    "# batch_size = 1 ensures that each item retried by the DataLoader will contain one sample from the dataset which in this case is one volume and one label\n",
    "\n",
    "# Test DataLoader\n",
    "for volume, label in dataloader:\n",
    "    # Squeeze out the batching dimension which is the first dimension\n",
    "    volume, label = volume.squeeze(0), label.squeeze(0) # Comment if permute block is commented above\n",
    "    print(\"Volume shape:\", volume.shape, \"Label shape:\", label.shape)\n",
    "    break # Checking only the first batch \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def create_data_loaders(dataset, batch_size=1):\n",
    "\n",
    "    # Determine sizes of each split\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.6 * total_size)\n",
    "    val_size = int(0.2 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Randomly split the dataset into train, cv, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(832) # Set seed\n",
    "    )\n",
    "\n",
    "    # Create data loaders for each split\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "dataset = MedicalImageDataset(image_root_dir, label_root_dir, transforms=transforms)\n",
    "train_loader, val_loader, test_loader = create_data_loaders(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Step [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Assuming dataloader is defined and ready to use\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m train_model(model, train_loader, criterion, optimizer)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, dataloader):\n\u001b[1;32m     40\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "# Define the Logistic Regression Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, num_features, num_outputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(num_features, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the image into a vector\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Initialize the Logistic Regression Model\n",
    "# num_outputs is the total number of voxels in a flattened volume\n",
    "num_features = 512 * 512 * 466  # Adjust based on actual volume size\n",
    "model = LogisticRegression(num_features=num_features, num_outputs=num_features)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (volumes, labels) in enumerate(train_loader):\n",
    "            volumes = volumes.view(volumes.size(0), -1)  # Flatten volumes\n",
    "            labels = labels.view(labels.size(0), -1)  # Flatten labels\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(volumes)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for volumes, labels in val_loader:\n",
    "            volumes = volumes.view(volumes.size(0), -1)  # Flatten volumes\n",
    "            labels = labels.view(labels.size(0), -1)  # Flatten labels\n",
    "\n",
    "            outputs = model(volumes)\n",
    "            predicted = outputs.round()  # Threshold the probabilities\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.numel()  # Total number of elements\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(dataset, batch_size=1)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from monai.data import Dataset, DataLoader\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from joblib import dump\n",
    "\n",
    "class FlattenTransform:\n",
    "    \"\"\"Transform to flatten the image volumes and labels for SVM input.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        volume, label = sample\n",
    "        # Flatten volume and label to 2D arrays\n",
    "        return volume.view(-1, volume.shape[-1]), label.view(-1)\n",
    "\n",
    "def train_svm_model(train_loader, C=1.0):\n",
    "    clf = svm.SVC(C=C, kernel='linear', probability=True)\n",
    "    for i, (volumes, labels) in enumerate(train_loader):\n",
    "        # Flatten the volumes and labels for SVM training\n",
    "        X_train, y_train = FlattenTransform()((volumes, labels))\n",
    "        X_train = X_train.numpy()  # Convert to numpy array for scikit-learn\n",
    "        y_train = y_train.numpy()\n",
    "        clf.fit(X_train, y_train)\n",
    "        print(f\"Batch {i+1} trained.\")\n",
    "    return clf\n",
    "\n",
    "def validate_svm_model(clf, val_loader):\n",
    "    total_acc = 0\n",
    "    for i, (volumes, labels) in enumerate(val_loader):\n",
    "        X_val, y_val = FlattenTransform()((volumes, labels))\n",
    "        X_val = X_val.numpy()  # Convert to numpy array for scikit-learn\n",
    "        y_val = y_val.numpy()\n",
    "        y_pred = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        total_acc += acc\n",
    "        print(f\"Validation accuracy for batch {i+1}: {acc:.2f}\")\n",
    "    average_acc = total_acc / len(val_loader)\n",
    "    print(f\"Average validation accuracy: {average_acc:.2f}\")\n",
    "\n",
    "\n",
    "clf = train_svm_model(train_loader)\n",
    "validate_svm_model(clf, val_loader)\n",
    "dump(clf, 'svm_pancreas_segmentation.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
